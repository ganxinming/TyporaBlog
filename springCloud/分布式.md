1.分布式锁

随着分布式应用出现，像以往加锁进行同步就失去了意义，因为分布式每个线程都不在一个同一个模块。所以需要保证一致性，需要分布式锁。分布式的CAP理论告诉我们“任何一个分布式系统都无法同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition tolerance），最多只能同时满足两项。”所以，很多系统在设计之初就要对这三者做出取舍。在互联网领域的绝大多数的场景中，都需要牺牲强一致性来换取系统的高可用性，系统往往只需要保证“最终一致性”，只要这个最终时间是在用户可以接受的范围内即可。

所以一般，我们保证的是最终一致性。

(其实很简单，因为原先的单个应用的锁失效了，所以只需要找到个大家都能共同访问的设备，这是实现分布式锁的基础，比如：数据库，redis)

#### 方案一：数据库实现分布式锁

例如对某方法加锁：在调用方法时，向表中插入一条数据(必包含方法名，和其他信息如：过期时间，描述等)。对方法名做唯一约束，保证只能有一条。

加锁：调用一个方法，则插入一条方法数据，进行加锁。解锁：则删除那个方法名数据。

如果存在则说明有人调用加锁了。

缺点：																									解决：												

1.单个数据库，如果挂了，直接不可用了。										两个数据库进行同步。		

2.没有失效时间的话，会导致如果解锁失败，其他线程永远不可用。表字段加上到期时间

3.这把锁非重入，当前线程不能在加锁。					数据库新加个字段来表示当前机器线程，下次可以直接调用

#### 方案二：redis实现分布式锁	

原理：调用方法前设置一个key-vlue的结构SET user_key user_value NX PX100

SET key value NX 效果等同于 SETNX key value				 **SETNX（set if not exist）**

其中，NX表示只有当键key不存在的时候才会设置key的值，PX表示设置键key的过期时间，单位是毫秒。当超过这个时间后，设置的键会自动失效	

因为这个是操作是原子性的，且NX自带非空不操作。

这个命令是只有在某个key不存在的时候，才会执行成功。那么当多个进程同时并发的去设置同一个key的时候，就永远只会有一个进程成功。

当某个进程设置成功之后，就可以去执行业务逻辑了，等业务逻辑执行完毕之后，再去进行解锁。

解锁很简单，只需要删除这个key就可以了，不过删除之前需要判断，这个key对应的value是当初自己设置的那个。

#### **方案三：zookeeper实现分布式锁**

首先来了解下zookeeper节点的概念

Zookeeper的数据存储结构就像一棵树，这棵树由节点组成，这种节点叫做Znode。

Znode分为四种类型：

1.持久节点 （PERSISTENT）

默认的节点类型。创建节点的客户端与zookeeper断开连接后，该节点依旧存在 。

2.持久节点顺序节点（PERSISTENT_SEQUENTIAL）

所谓顺序节点，就是在创建节点时，Zookeeper根据创建的时间顺序给该节点名称进行编号：

3.临时节点（EPHEMERAL）

和持久节点相反，当创建节点的客户端与zookeeper断开连接后，临时节点会被删除。

**4.临时顺序节点（EPHEMERAL_SEQUENTIAL）**

顾名思义，临时顺序节点结合和临时节点和顺序节点的特点：在创建节点时，Zookeeper根据创建的时间顺序给该节点名称进行编号；当创建节点的客户端与zookeeper断开连接后，临时节点会被删除。

实现分布式锁：正是利用了临时顺序节点。

过程：第一个线程client1进来创建临时顺序节点lock1，之后，Client1查找ParentLock下面所有的临时顺序节点并排序，判断自己所创建的节点Lock1是不是顺序最靠前的一个。如果是第一个节点，则成功获得锁。这时候，如果再有一个客户端 Client2 前来获取锁，则在ParentLock下载再创建一个临时顺序节点Lock2。Client2查找ParentLock下面所有的临时顺序节点并排序，判断自己所创建的节点Lock2是不是顺序最靠前的一个，结果发现节点Lock2并不是最小的。

于是，Client2向排序仅比它靠前的节点Lock1注册Watcher，用于监听Lock1节点是否存在。这意味着Client2抢锁失败，进入了等待状态。

（总结：进入zookeeper，先创建节点，此节点按时间排序，最小的就是最先进来的。调用方法前，就去查看是否当前最小节点就是自己，如果是就进入使用完就删除节点，如果不是等待。）

#### 从理解的难易程度角度（从低到高）

数据库 > 缓存 > Zookeeper

#### 从实现的复杂性角度（从低到高）

Zookeeper >= 缓存 > 数据库

#### 从性能角度（从高到低）

缓存 > Zookeeper >= 数据库

#### 从可靠性角度（从高到低）

Zookeeper > 缓存 > 数据库

2.分布式事务

为什么会出现这个问题？

假如订单服务，和库存减少分为两个服务。当下订单时，库存应该减少。但是现在，订单下了，通知库存减少，这是没问题的。但是分布式下，两个服务你怎么保证两个事务都能执行成功？说白了，原先这些操作在一台机器上，可以用一个事务管理。现在分成两台机器了，无法保证两个事务同时成功。所以我们要做的就是保证所有分布式的事务一起成功。

1.基于XA协议的两阶段提交方案。

在XA中包含两个角色：事务协调者和事务参与者(即分布式机器)。

一阶段：事务协调者向所有分布式发送一个prepare请求，机器收到后不急着回复，先执行自己的事务，如果事务成功，先不commit提交事务，先返回成功信号，等待通知是否提交事务。如果失败，返回失败信号。

二阶段：事务协调者接受到所有事务是否成功的信号，如果都成功了，则发出提交commit请给事务参与者，之后他们就可以提交事务了。如果有失败信号，说明有人失败了，则发出回滚操作给所有事务参与者，则他们都回滚。

(总结：其实二段提交就是利用了事务最后commit的那个时间点，如果成功，先不commit，等待通知。如果所有人都成功，则让所有事务提交)

缺点：：

1.性能受到很大影响，你想，所有快的事务却要等待最慢的那个事务。所以一般不适用分布式应用。

2.单点故障。由于协调者的重要性，一旦协调者发生故障，所有参与者就一直阻塞状态。



2.三阶段提交方案

在二阶段基础上，增加了超时机制，如果超时未接到协调者信息，自己提交。(解决单点故障)



3.TCC方案

4.GTS(阿里巴巴消息中间件)